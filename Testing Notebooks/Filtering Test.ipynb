{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_helpers2 import run_test, run_fairness_curve\n",
    "import numpy as npb\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': {'bonjour': 'french'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDict = {'hi': {'hola':'spanish', 'bonjour':'french'}}\n",
    "newDict = copy.deepcopy(myDict)\n",
    "del newDict['hi']['hola']\n",
    "newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load rules\n",
    "with open('results/FairnessRuns-Eps:0.01_rules.txt') as json_file:\n",
    "    rules = np.array(json.load(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataInfo = {\n",
    "    'file': 'data/german.csv',\n",
    "    'groupCol': 'gender'\n",
    "}\n",
    "globalArgs = {\n",
    "    'num_splits': 10,\n",
    "}\n",
    "\n",
    "tests = []\n",
    "for eps in [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.1, 0.2, 0.5, 1]:\n",
    "    test_params = {\n",
    "            'price_limit': 10,\n",
    "            'train_limit': 10,\n",
    "            'fixed_model_params': {\n",
    "                'ruleGenerator': 'DNF_IP',\n",
    "                'numRulesToReturn': 100,\n",
    "                'epsilon': eps,\n",
    "                'fairness_module': 'EqOfOp'\n",
    "            },\n",
    "            'num_hp_splits': 3,\n",
    "            'name': 'FairnessRuns-Eps:'+str(eps),\n",
    "            'hyper_paramaters': {\n",
    "                'ruleComplexity': [5,10,17, 20]\n",
    "            }\n",
    "        }\n",
    "    tests.append(test_params)\n",
    "\n",
    "results, _ = run_fairness_curve(tests, globalArgs, dataInfo, rules, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results = []\n",
    "for res in results:\n",
    "    summary_results.append([res.name.split(':')[-1],  res.res['mean_accuracy'], res.res['std_accuracy']])\n",
    "pd.DataFrame(summary_results, columns = ['epsilon', 'mean_accuracy',  'std_accuracy']).to_csv('results/german.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
